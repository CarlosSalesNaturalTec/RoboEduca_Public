<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Robô Educa</title>
</head>

<body>

    <!-- Audio In -->
    <audio id="audioIn"></audio>
    <audio id="audioOut" preload="none"></audio>
    <br>

    <br><br>

    <!-- Div Mensagens -->
    <div id="divMessages"></div>

    <script>

        //const urlServer = 'https://codeengine-application-d0.t6vw6163k3t.us-east.codeengine.appdomain.cloud/watson_server';     // URL do servidor Watson (POST upload Audio)
        //const urlAudio = 'https://codeengine-application-d0.t6vw6163k3t.us-east.codeengine.appdomain.cloud/audio?filename=';    // URL do servidor Watson (GET Audio Resposta)
        const urlServer = 'http://localhost:3000/watson_server';     // URL do servidor Watson (POST upload Audio)
        const urlAudio = 'http://localhost:3000/audio?filename=';    // URL do servidor Watson (GET Audio Resposta)

        const audioIn = document.getElementById('audioIn');
        const audioOut = document.getElementById('audioOut');     

        const volumeMin = 0.002;
        var audioData = undefined;
        var recording = false;
        var lenResposta = 0;        

        // Em caso de microfone ter sido detectado
        const handleSuccess = function (stream) {

            var audioTracks = stream.getAudioTracks();
            displayMessage('Utilizando audio device/microfone: ' + audioTracks[0].label);

            // Em caso de finalização do Stream
            stream.onremovetrack = function () {
                displayMessage('Streaming finalizado');
            };

            // torna as variáveis disponíveis para o Console do navegador
            window.stream = stream;

            // adiciona som do Microfone ao elemento audioIn
            if ("srcObject" in audioIn) {
                audioIn.srcObject = stream;
            }
            else {
                // Old version   
                audioIn.src = window.URL
                    .createObjectURL(stream);
            }

            // parâmetros utiizados na gravação da fala do usuário
            const options = { mimeType: 'audio/webm' };
            let recordedChunks = [];
            const mediaRecorder = new MediaRecorder(stream, options);

            //#region - Análise de Volume de entrada do audio
            const audioContext = new AudioContext();
            const mediaStreamAudioSourceNode = audioContext.createMediaStreamSource(stream);
            const analyserNode = audioContext.createAnalyser();
            mediaStreamAudioSourceNode.connect(analyserNode);

            var initialTime = 0;
            var finalTime = 0;

            const pcmData = new Float32Array(analyserNode.fftSize);
            const onFrame = () => {
                analyserNode.getFloatTimeDomainData(pcmData);
                let sumSquares = 0.0;
                for (const amplitude of pcmData) { sumSquares += amplitude * amplitude; }
                let audioInvolume = Math.sqrt(sumSquares / pcmData.length);

                if (audioInvolume >= volumeMin && recording == false) {
                    recording = true;
                    clearMessages();
                    displayMessage("Iniciando gravação de audio.");
                    mediaRecorder.start();
                    initialTime = Date.now();
                }

                if (audioInvolume < volumeMin && recording == true ) {
                    finalTime = Date.now();
                    let timeElapsed = (finalTime - initialTime) ;
                    if (timeElapsed >=1000 ) {
                        recording = false;
                        displayMessage("Parando gravação do audio.");
                        mediaRecorder.stop();    
                    }
                }

                window.requestAnimationFrame(onFrame);
            };
            window.requestAnimationFrame(onFrame);
            //#endregion

            // Na medida que preenche buffer com audio, adiciona em array
            mediaRecorder.addEventListener('dataavailable', function (e) {
                if (e.data.size > 0) {
                    recordedChunks.push(e.data);
                    displayMessage("Preenchendo Buffer.");
                }
            });

            // Quando gravação é concluida
            mediaRecorder.addEventListener('stop', function () {
                // blob of type mp3
                audioData = new Blob(recordedChunks, { 'type': 'audio/mp3;' });
                //limpa memória
                recordedChunks = [];
                // envio de audio para transcrição
                enviar();
            });

        };

        // Envio de audio para transcrição
        function enviar() {

            let initialTime = Date.now();

            displayMessage('Enviando audio para transcrição, aguarde...');

            let formData = new FormData();
            let nomeFile = "record_" + Date.now();
            formData.append("fileupload", audioData, nomeFile);

            var xhr = new XMLHttpRequest();
            xhr.open('POST', urlServer, true);

            xhr.timeout = 10000; // tempo máximo para aguardar resposta (em milliseconds)

            xhr.onreadystatechange = function (oEvent) {
                if (xhr.readyState === 4) {
                    if (xhr.status === 200) {
                        let objResp = JSON.parse(xhr.response);
                        let transcricao = objResp.watson_transcricao;
                        let resposta = objResp.watson_resposta;
                        let audioFile = objResp.audio_file;
                        lenResposta = resposta.length;

                        displayMessage('Transcrição: ' + transcricao);
                        displayMessage('Resposta: ' + resposta);
                        displayMessage('Audio File: ' + audioFile);

                        getAudioResponse(objResp.audio_file);
                    } else {
                        displayMessage('Erro no envio do audio para transcrição.');
                    }
                    let finalTime = Date.now();
                    let timeElapsed = (finalTime - initialTime) / 1000;
                    displayMessage("Tempo de resposta: " + timeElapsed + "seg");
                    displayMessage("------------");
                }
            };

            xhr.send(formData);

        }

        // Exibir mensagem de status
        function displayMessage(message) {
            var element = document.getElementById("divMessages");
            element.innerHTML += message + "<br>";
        }

        function clearMessages() {
            document.getElementById("divMessages").innerHTML = "";
        }

        // Obtem audio da resposta
        function getAudioResponse(fileName) {
            const audioPath = urlAudio + fileName;
            audioOut.src = audioPath;

            if (lenResposta <= 50) { setTimeout(playAudio, 1000); }
            if (lenResposta > 50 && lenResposta <= 80) { setTimeout(playAudio, 2000); }
            if (lenResposta > 80 && lenResposta <= 150) { setTimeout(playAudio, 3000); }
            if (lenResposta > 150) { setTimeout(playAudio, 4000); }
        }

        // Play no audio da resposta
        function playAudio() {
            audioOut.play();
        }

        // Adquirir acesso ao microfone
        navigator.mediaDevices
            .getUserMedia({ audio: true, video: false })
            .then(handleSuccess)
            .catch(function (err) {
                console.log(err.name, err.message);
                displayMessage(err.message);
            });

    </script>

</body>

</html>